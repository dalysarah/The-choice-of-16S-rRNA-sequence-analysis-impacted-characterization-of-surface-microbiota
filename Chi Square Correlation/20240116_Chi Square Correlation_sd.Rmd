---
title: "Chi"
author: "Sarah Daly"
date: "2023-10-26"
output: html_document
editor_options: 
  chunk_output_type: console
---

Purpose:  Generate figure of Chi Square Correlation test of Environmental Sampling Data; Generate p-value; Find percent agreement of samples

Input Files:  
Final_Combined_Metadata.csv
melt.txt

#Set WD and load data
```{r}
setwd("C:/Users/dalys/OneDrive/Documents/My Documents/Cornell Postdoc Papers/Review paper/Manuscript/Code/Chi Square Correlation")
```

#load libraries 
```{r}
library(dplyr)
library(tidyr) 
```

#Load and Filter data
```{r}
df<- read.csv("Metadata .csv" , na.strings="NA")

samples_keep = read.csv("keep_samples.csv")

#300 samples kept 
target<- samples_keep$ID

#Keep those 300 selected samples 
df2 <- df %>% 
  filter(sample.id %in% target)

dim(df2) #Should be 300 long 
```

#Find % Agreement between objects per density categroy classification 
```{r}
ID<- unique(df2$Original.ID)
Fac<- unique(df2$Facility)
df2$Original.ID <- as.character(df2$Original.ID)

List<- list()

df2$Original.ID <- as.character(df2$Original.ID)

for (item in ID){
#Sort by ID
df_filtered= df2[df2$Original.ID == item, ]

#Only if metadata has more than one point 
if(dim(df_filtered)[1]!=1) {
for (item2 in Fac) 
  #Filter by Facility 
 df_filtered_loc= df_filtered[df_filtered$Facility == item2, ]
 #Are all the bins the same?
 consis = (length(df_filtered_loc$Fill_bins) ==1)
 List[[length(List)+1]] = consis
}
}

#Proportion of consistent objects 
hat_check <-unlist(List)
hat_check
per= round(sum(hat_check==TRUE) / length(hat_check), 4) 
per

capture.output(per , file=paste("% non consistant swabbing.txt"))
```

#Sort Data by Object and Fill Bins
```{r}
d<- df2 %>% group_by(Object, Fill_bins) %>%
    summarise(n = n())   #Get number of samples in each group
d = as.data.frame(d) #Convert to data frame 

#Write to .csv
write.csv(d, "No Count Object and Fill Bins.csv") #Transform these results to "melt.txt"

#Import File--Manually transform data in excel from "d"
mf <- read.delim("melt.txt", row.names = 1)

#Compute chi-square test in R
#Chi-square statistic can be easily computed using the function chisq.test() as follow:
head(mf)
chisq <- chisq.test(mf)
chisq # row and the column variables are statistically significantly associated (p-value = 0)

capture.output(chisq , file=paste("Chi Square statistic APC category and object type.txt"))

# Observed counts
chisq$observed

library(corrplot)
corrplot(chisq$residuals, is.cor = FALSE,tl.col="black",tl.cex=1.5, cl.cex=1.5,tl.offset = 1,cl.pos="r", cl.ratio = 0.2, cl.align.text = 'l', addgrid.col = "black")


#Positive residuals are in blue. Positive values in cells specify an attraction (positive association) between the corresponding row and column variables
tiff(paste("Chi corrPlot-Large font.tif", sep=" "), res=300, compression = "lzw", height=9, width=10, units="in")
print(corrplot(chisq$residuals, is.cor = FALSE,tl.col="black",tl.cex=1.5, cl.cex=1.5,tl.offset = 1,cl.pos="r", cl.ratio = 0.2, cl.align.text = 'l', addgrid.col = "black"))
dev.off()

pdf(paste("Chi corrPlot-Large font.pdf", sep=" "))
print(corrplot(chisq$residuals, is.cor = FALSE,tl.col="black",tl.cex=1.5, cl.cex=1.5,tl.offset = 1,cl.pos="r", cl.ratio = 0.2, cl.align.text = 'l', addgrid.col = "black"))
dev.off()
```
